# Pia AI ‚Äì Voice-to-Voice med Streamlit (f√∂r Colab)

# üì¶ Steg 1: Installera n√∂dv√§ndiga bibliotek
!pip install git+https://github.com/openai/whisper.git
!pip install piper-tts streamlit streamlit-webrtc transformers torchaudio
!apt-get install -y espeak ffmpeg

# üì• Steg 2: Ladda svensk r√∂st till Piper
!mkdir -p ~/.local/share/piper/voices
!wget -O ~/.local/share/piper/voices/sv-SE-jenny-low.onnx https://huggingface.co/rhasspy/piper-voices/resolve/main/sv/sv-SE-jenny-low.onnx

# üß† Steg 3: Ladda AI-modell (TinyLlama)
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
model_name = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)
generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

# üéôÔ∏è Steg 4: Starta Streamlit-app
code = '''
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, ClientSettings
import whisper
import torch
import os
import av
import queue
import threading
import pyaudio
import wave
import time
from transformers import pipeline

# Initiera Whisper och r√∂stmodell
whisper_model = whisper.load_model("base")
piper_voice = "~/.local/share/piper/voices/sv-SE-jenny-low.onnx"

# Laddad textgenerator
generator = pipeline("text-generation", model="TinyLlama/TinyLlama-1.1B-Chat-v1.0")

# Gr√§nssnitt
st.title("üéôÔ∏è Prata med Pia")
st.write("S√§g n√•got till Pia ‚Äì hon svarar med sin r√∂st.")

# Mikrofoninspelning
if "audio_buffer" not in st.session_state:
    st.session_state.audio_buffer = []

def callback(frame):
    st.session_state.audio_buffer.append(frame.to_ndarray().tobytes())
    return frame

webrtc_streamer(key="mic", mode=WebRtcMode.SENDONLY, in_audio=True, client_settings=ClientSettings(media_stream_constraints={"audio": True, "video": False}), audio_receiver_size=256, rtc_configuration={}, video_frame_callback=callback)

if st.button("üé§ Skicka till Pia"):
    filename = "pia_input.wav"
    with wave.open(filename, "wb") as f:
        f.setnchannels(1)
        f.setsampwidth(2)
        f.setframerate(44100)
        f.writeframes(b"".join(st.session_state.audio_buffer))

    result = whisper_model.transcribe(filename)
    input_text = result['text']
    st.write(f"Du sa: {input_text}")

    reply = generator(input_text, max_new_tokens=100)[0]['generated_text']
    st.write(f"Pia: {reply}")

    tts_cmd = f"piper --model {piper_voice} --text \"{reply}\" --output_file pia_reply.wav"
    os.system(tts_cmd)

    audio_file = open("pia_reply.wav", "rb")
    audio_bytes = audio_file.read()
    st.audio(audio_bytes, format='audio/wav')
'''

with open("app.py", "w") as f:
    f.write(code)

# ‚ñ∂Ô∏è Starta Streamlit i bakgrunden
!streamlit run app.py &
